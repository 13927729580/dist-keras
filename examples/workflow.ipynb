{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Keras *\n",
    "<sub>* Lack of a better name, but at least it describes what it is :)</sub>\n",
    "\n",
    "**Joeri Hermans** (Technical Student, IT-DB-SAS, CERN)             \n",
    "*Departement of Knowledge Engineering*         \n",
    "*Maastricht University, The Netherlands*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!(date +%d\\ %B\\ %G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This presentation will give the reader an introduction to the topic of distributed deep learning (DDL) and to the issues which need to be taken into consideration when applying this technique. Furthermore, we will introduce a DDL framework based on [Apache Spark](https://spark.apache.org/) and [Keras](https://keras.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Introduction and problem statement](#Distributed-Deep-Learning,-an-introduction.)\n",
    "  - [Model parallelism](#Model-parallelism)\n",
    "  - [Data parallelism](#Data-parallelism)\n",
    "- [Conclusion](#Conclusion)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Deep Learning, an introduction.\n",
    "\n",
    "Unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. However, consider the problem of training a deep network with billions of parameters. How do we achieve this without waiting for days, or even weeks, and thus leaving more time to tune the model? Dean et al. [[1]](https://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf) proposed an training paradigm which allows us to train a model on multiple physical machines. The authors describe two methods to achieve this, i.e., **data parallelism** and **model parallelism**<sup>1</sup>.\n",
    "\n",
    "### Model parallelism\n",
    "\n",
    "In model parallelism a *single* model is distributed over multiple machines. The performance benefits of distributeing a deep network across multiple machines depends on the connectivity structure and computational needs of the model. Models with a large number of parameters typically benefit from access to more CPUs and memory, up to the point where communication costs, i.e., propagation of the weight updates and synchronization mechanisms, dominate [[1]](https://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf).\n",
    "\n",
    "![Model Parallelism](../resources/model_parallelism.png)\n",
    "\n",
    "### Data parallelism\n",
    "\n",
    "TODO\n",
    "\n",
    "![Data Parallelism](../resources/data_parallelism.png)\n",
    "\n",
    "<sub>**1:** Hybrids are possible as well.</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from distkeras.distributed import *\n",
    "from distkeras.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modify these variables according to your needs.\n",
    "application_name = \"Distributed Keras Notebook\"\n",
    "using_spark_2 = False\n",
    "yarn = \"p01001532067275.cern.ch:8088\" # Address:port of ResourceManager\n",
    "if not yarn:\n",
    "    # Tell master to use local resources.\n",
    "    master = \"local[*]\"\n",
    "    num_cores = 3\n",
    "    num_executors = 1\n",
    "else:\n",
    "    # Tell master to use YARN.\n",
    "    master = \"yarn-client\"\n",
    "    max_num_executors = 7\n",
    "    num_cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if YARN is specified.\n",
    "if yarn:\n",
    "    # Build the ResourceManager metrics URI.\n",
    "    yarn_metrics_uri = \"http://\" + yarn + \"/ws/v1/cluster/metrics\"\n",
    "    # Fetch the number of available nodes\n",
    "    response = requests.get(yarn_metrics_uri)\n",
    "    data = response.json()\n",
    "    # Fetch the number of active nodes.\n",
    "    num_active_nodes = int(data['clusterMetrics']['activeNodes'])\n",
    "    # Assign the number of executors.\n",
    "    num_executors = num_active_nodes\n",
    "    if num_executors > max_num_executors:\n",
    "        num_executors = max_num_executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This variable is derived from the number of cores and executors, and will \n",
    "# be used to assign the number of model trainers.\n",
    "num_workers = num_executors * num_cores\n",
    "\n",
    "print(\"Number of desired executors: \" + `num_executors`)\n",
    "print(\"Number of desired cores / executor: \" + `num_cores`)\n",
    "print(\"Total number of workers: \" + `num_workers`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-csv_2.10:1.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a Spark Context\n",
    "\n",
    "In order to read our (big) dataset into our Spark Cluster, we first need a Spark Context. However, since Spark 2.0 there are some changes in the initialization of a Spark Context. For example, SQLContext and HiveContext do not have to be initialized seperatly anymore, i.e., the initialization process is simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", application_name)\n",
    "conf.set(\"spark.master\", master)\n",
    "conf.set(\"spark.executor.cores\", `num_cores`)\n",
    "conf.set(\"spark.executor.instances\", `num_executors`)\n",
    "conf.set(\"spark.locality.wait\", \"0\")\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\");\n",
    "\n",
    "# Check if the user is running Spark 2.0 +\n",
    "if using_spark_2:\n",
    "    sc = SparkSession.builder.config(conf=conf) \\\n",
    "            .appName(application_name) \\\n",
    "            .getOrCreate()\n",
    "else:\n",
    "    # Create the Spark context.\n",
    "    sc = SparkContext(conf=conf)\n",
    "    # Add the missing imports\n",
    "    from pyspark import SQLContext\n",
    "    sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if we are using Spark 2.0\n",
    "if using_spark_2:\n",
    "    reader = sc\n",
    "else:\n",
    "    reader = sqlContext\n",
    "# Read the dataset.\n",
    "raw_dataset = reader.read.format('com.databricks.spark.csv') \\\n",
    "                    .options(header='true', inferSchema='true').load(\"data/atlas_higgs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Double-check the inferred schema.\n",
    "raw_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preprocessing and normalization\n",
    "\n",
    "Since Spark's MLlib has some nice features for some distributed dataprocessing, we follow MLlib (dataframe) API in order to ensure compatibility. What it basically boils down to, is that all the features (which can have different type) will be aggregated into a single column. More information on Spark MLlib (and other APIs) can be found here: [http://spark.apache.org/docs/latest/ml-guide.html](http://spark.apache.org/docs/latest/ml-guide.html)\n",
    "\n",
    "In the following steps we will show you how to extract the desired columns from the dataset and prepare the for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we would like to extract the desired features from the raw dataset.\n",
    "# We do this by constructing a list with all desired columns.\n",
    "features = raw_dataset.columns\n",
    "features.remove('EventId')\n",
    "features.remove('Weight')\n",
    "features.remove('Label')\n",
    "# Next, we use Spark's VectorAssembler to \"assemble\" (create) a vector of all desired features.\n",
    "# http://spark.apache.org/docs/latest/ml-features.html#vectorassembler\n",
    "vector_assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "# This transformer will take all columns specified in features, and create an additional column \"features\"\n",
    "# which will contain all the desired features aggregated into a single vector.\n",
    "dataset = vector_assembler.transform(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply feature normalization with standard scaling. This will transform a feature to have mean 0, and std 1.\n",
    "# http://spark.apache.org/docs/latest/ml-features.html#standardscaler\n",
    "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_normalized\", withStd=True, withMean=True)\n",
    "standard_scaler_model = standard_scaler.fit(dataset)\n",
    "dataset = standard_scaler_model.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If we look at the dataset, the Label column consists of 2 entries, i.e., b (background), and s (signal).\n",
    "# Our neural network will not be able to handle these characters, so instead, we convert it to an index\n",
    "# so we can indicate that output neuron with index 0 is background, and 1 is signal.\n",
    "# http://spark.apache.org/docs/latest/ml-features.html#stringindexer\n",
    "label_indexer = StringIndexer(inputCol=\"Label\", outputCol=\"label_index\").fit(dataset)\n",
    "dataset = label_indexer.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some properties of the neural network for later use.\n",
    "nb_classes = 2 # Number of output classes (signal and background)\n",
    "nb_features = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We observe that Keras is not able to work with these indexes. What it actually\n",
    "# expects is a vector with an identical size to the output layer. Our framework provides\n",
    "# functionality to do this with ease. What it basically does, given an expected vector dimension,\n",
    "# it prepares zero vector with the specified dimensionality, and will set the neuron with a specific\n",
    "# label index to one.\n",
    "\n",
    "# For example:\n",
    "# 1. Assume we have a label index: 3\n",
    "# 2. Output dimensionality: 5\n",
    "# With these parameters, we obtain the following vector in the DataFrame column: [0,0,0,1,0]\n",
    "\n",
    "label_vector_transformer = LabelVectorTransformer(output_dim=nb_classes, input_col=\"label_index\", output_col=\"label\")\n",
    "dataset = label_vector_transformer.transform(dataset).toDF()\n",
    "# Only select the columns we need (less data shuffling) while training.\n",
    "dataset = dataset.select(\"features_normalized\", \"label_index\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shuffle the dataset.\n",
    "dataset = shuffle(dataset)\n",
    "\n",
    "# Note: we also support shuffling in the trainers by default.\n",
    "# However, since this would require a shuffle for every training we will only do it once here.\n",
    "# If you want, you can enable the training shuffling by specifying shuffle=True in the train() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, we create a trainingset and a testset.\n",
    "(trainingSet, testSet) = dataset.randomSplit([0.7, 0.3])\n",
    "trainingSet.cache()\n",
    "testSet.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction\n",
    "\n",
    "We will now construct a relatively simple Keras model (without any modifications) which, hopefully, will be able to classify the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(600, input_shape=(nb_features,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(600))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Summarize the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Optimizer and Loss\n",
    "\n",
    "In order to evaluate the gradient on the model replicas, we have to specify an optimizer and a loss method. For this, we just follow the Keras API as defined in the documentation: [https://keras.io/optimizers/](https://keras.io/optimizers/) and [https://keras.io/objectives/](https://keras.io/objectives/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = 'adagrad'\n",
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "In the following cells we will train and evaluate the model using different distributed trainers, however, we will as well provide a baseline metric using a **SingleTrainer**, which is basically an instance of the Adagrad optimizer running on Spark.\n",
    "\n",
    "Furthermore, we will also evaluate every training using Spark's MulticlassClassificationEvaluator [https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator\n",
    "\n",
    "We will evaluate all algorithms using the F1 [https://en.wikipedia.org/wiki/F1_score](https://en.wikipedia.org/wiki/F1_score) metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric_name = \"f1\"\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=metric_name, predictionCol=\"predicted_index\", labelCol=\"label_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    global testSet\n",
    "    \n",
    "    # Clear the prediction column from the testset.\n",
    "    testSet = testSet.select(\"features_normalized\", \"label_index\", \"label\")\n",
    "    # Apply a prediction from a trained model.\n",
    "    predictor = ModelPredictor(keras_model=trained_model, features_col=\"features_normalized\")\n",
    "    testSet = predictor.predict(testSet).toDF()\n",
    "    # Transform the prediction vector to an indexed label.\n",
    "    testSet = index_transformer.transform(testSet).toDF()\n",
    "    # Store the F1 score of the SingleTrainer.\n",
    "    score = evaluator.evaluate(testSet)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, before we can evaluate the prediction, we will also need to converted the neural network prediction, which is a vector which has the same dimensionality as the output layer, to a label index. This is shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_transformer = LabelIndexTransformer(output_dim=nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also have to keep track of the evaluated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "time_spent = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distribute the training and test set to the workers.\n",
    "testSet = testSet.repartition(num_workers)\n",
    "trainingSet = trainingSet.repartition(num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SingleTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "single_trainer = SingleTrainer(keras_model=model, loss=loss, worker_optimizer=optimizer, \n",
    "                               features_col=\"features_normalized\", num_epoch=1, batch_size=64)\n",
    "trained_model = single_trainer.train(trainingSet)\n",
    "dt = time.time() - time_start\n",
    "time_spent['single_trainer'] = dt\n",
    "\n",
    "# Note that this time also includes shuffling the data from different places. If you run this\n",
    "# for the second time (after each other), it will be a lot faster since the data is already\n",
    "# on the physical machine.\n",
    "print(\"Time spent (SingleTrainer): \" + `dt` + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = evaluate(trained_model)\n",
    "results['single_trainer'] = score\n",
    "\n",
    "print(\"F1 (SingleTrainer): \" + `score`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EASGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "easgd_trainer = EASGD(keras_model=model, loss=loss, worker_optimizer=optimizer, \n",
    "                      features_col=\"features_normalized\", batch_size=64, num_epoch=1,\n",
    "                      num_workers=num_workers, rho=5.0, learning_rate=0.04)\n",
    "trained_model = easgd_trainer.train(trainingSet)\n",
    "dt = time.time() - time_start\n",
    "time_spent['easgd_trainer'] = dt\n",
    "\n",
    "print(\"Time spent (EASGD): \" + `dt` + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = evaluate(trained_model)\n",
    "results['easgd_trainer'] = score\n",
    "\n",
    "print(\"F1 (EASGD): \" + `score`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous EASGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "async_easgd_trainer = AsynchronousEASGD(keras_model=model, features_col=\"features_normalized\",\n",
    "                                        batch_size=10, num_workers=num_workers, rho=5.0, learning_rate=0.05,\n",
    "                                        worker_optimizer=optimizer, loss=loss, communication_window=30)\n",
    "trained_model = async_easgd_trainer.train(trainingSet)\n",
    "dt = time.time() - time_start\n",
    "time_spent['async_easgd_trainer'] = dt\n",
    "\n",
    "print(\"Time spent (Asynchronous EASGD): \" + `dt` + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = evaluate(trained_model)\n",
    "results['async_easgd_trainer'] = score\n",
    "\n",
    "print(\"F1 (Asynchronous EASGD): \" + `score`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous EAMSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "async_eamsgd_trainer = AsynchronousEAMSGD(keras_model=model, features_col=\"features_normalized\",\n",
    "                                          batch_size=10, num_workers=num_workers, rho=5.0, learning_rate=0.05,\n",
    "                                          worker_optimizer=optimizer, loss=loss, communication_window=10, momentum=0.85)\n",
    "trained_model = async_eamsgd_trainer.train(trainingSet)\n",
    "dt = time.time() - time_start\n",
    "time_spent['async_eamsgd_trainer'] = dt\n",
    "\n",
    "print(\"Time spend (Asynchronous EAMSGD): \" + `dt` + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = evaluate(trained_model)\n",
    "results['async_eamsgd_trainer'] = score\n",
    "\n",
    "print(\"F1 (Asynchronous EAMSGD): \" + `score`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOWNPOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "downpour_trainer = DOWNPOUR(keras_model=model, worker_optimizer=optimizer, loss=loss, features_col=\"features_normalized\", batch_size=62,\n",
    "                   num_workers=num_workers, learning_rate=0.05)\n",
    "trained_model = downpour_trainer.train(trainingSet)\n",
    "dt = time.time() - time_start\n",
    "time_spent['downpour_trainer'] = dt\n",
    "\n",
    "print(\"Time spent (DOWNPOUR): \" + `dt` + \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = evaluate(trained_model)\n",
    "results['downpour_trainer'] = score\n",
    "\n",
    "print(\"F1 (DOWNPOUR): \" + `score`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of initial experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the F1 score of the trainers.\n",
    "plt.bar(range(len(results)), results.values(), 0.2, align='center', color='b')\n",
    "plt.xticks(range(len(results)), results.keys(), rotation=25)\n",
    "plt.xlabel('Trainers')\n",
    "plt.ylabel('F1')\n",
    "plt.title(\"F1 score with different trainers - (higher is better)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the training time of the trainers.\n",
    "plt.bar(range(len(time_spent)), time_spent.values(), 0.2, align='center', color='b')\n",
    "plt.xticks(range(len(time_spent)), time_spent.keys(), rotation=25)\n",
    "plt.xlabel('Trainers')\n",
    "plt.ylabel('Seconds')\n",
    "plt.title(\"Training time - (lower is better)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of parallel workers: \" + `num_workers`)\n",
    "improvement = (time_spent['single_trainer'] / time_spent['async_easgd_trainer']) * 100.0\n",
    "print(\"Improvement using AEASGD: \" + `improvement` + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "## References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
